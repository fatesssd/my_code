{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d59478b-d2f1-4096-be31-2151a80433f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/4200, Loss: 50042295333.3723\n",
      "Epoch 101/4200, Loss: 7019335268.9051\n",
      "Epoch 201/4200, Loss: 5091180203.9124\n",
      "Epoch 301/4200, Loss: 4425443774.5985\n",
      "Epoch 401/4200, Loss: 4224250856.6423\n",
      "Epoch 501/4200, Loss: 4140403783.9416\n",
      "Epoch 601/4200, Loss: 4056214242.1022\n",
      "Epoch 701/4200, Loss: 3988752151.3577\n",
      "Epoch 801/4200, Loss: 3988402248.8759\n",
      "Epoch 901/4200, Loss: 3938023864.9927\n",
      "Epoch 1001/4200, Loss: 3908475706.8613\n",
      "Epoch 1101/4200, Loss: 3880205617.5182\n",
      "Epoch 1201/4200, Loss: 3837577094.5401\n",
      "Epoch 1301/4200, Loss: 3854102798.0146\n",
      "Epoch 1401/4200, Loss: 3855905060.4380\n",
      "Epoch 1501/4200, Loss: 3874655658.0438\n",
      "Epoch 1601/4200, Loss: 3830316645.8394\n",
      "Epoch 1701/4200, Loss: 3790127269.3723\n",
      "Epoch 1801/4200, Loss: 3893784390.0730\n",
      "Epoch 1901/4200, Loss: 3789117884.7299\n",
      "Epoch 2001/4200, Loss: 3799993225.3431\n",
      "Epoch 2101/4200, Loss: 3835575928.5255\n",
      "Epoch 2201/4200, Loss: 3805483940.4380\n",
      "Epoch 2301/4200, Loss: 3807232713.8102\n",
      "Epoch 2401/4200, Loss: 3768659049.5766\n",
      "Epoch 2501/4200, Loss: 3765721669.1387\n",
      "Epoch 2601/4200, Loss: 3813122678.6569\n",
      "Epoch 2701/4200, Loss: 3759560564.7883\n",
      "Epoch 2801/4200, Loss: 3757792630.6569\n",
      "Epoch 2901/4200, Loss: 3767374303.2993\n",
      "Epoch 3001/4200, Loss: 3703060760.2920\n",
      "Epoch 3101/4200, Loss: 3737831874.3358\n",
      "Epoch 3201/4200, Loss: 3728734983.4745\n",
      "Epoch 3301/4200, Loss: 3690965906.6861\n",
      "Epoch 3401/4200, Loss: 3801363178.5109\n",
      "Epoch 3501/4200, Loss: 3744936929.1679\n",
      "Epoch 3601/4200, Loss: 3690243689.5766\n",
      "Epoch 3701/4200, Loss: 3712353500.4964\n",
      "Epoch 3801/4200, Loss: 3754872991.7664\n",
      "Epoch 3901/4200, Loss: 3708896952.9927\n",
      "Epoch 4001/4200, Loss: 3691802410.9781\n",
      "Epoch 4101/4200, Loss: 3649644102.0730\n",
      "R^2 (Train): 0.7381\n",
      "R^2 (Test): 0.7003\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 加载数据\n",
    "df = pd.read_csv('housing.csv')\n",
    "X = df[['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', \n",
    "        'population', 'households', 'median_income']].values\n",
    "y = df['median_house_value'].values\n",
    "\n",
    "# 转换为 PyTorch 数据集\n",
    "class HousingDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = HousingDataset(X, y)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# 数据加载器\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 定义神经网络\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)  # 输出为1维\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x).squeeze()  # squeeze去掉多余的维度\n",
    "\n",
    "# 初始化网络、损失函数和优化器\n",
    "input_dim = X.shape[1]\n",
    "model = NeuralNetwork(input_dim).to(device)  # 将模型移到 GPU\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练网络\n",
    "epochs = 4200\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # 将数据移到 GPU\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    if epoch%100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 计算 R^2 分数\n",
    "def calculate_r2(loader, model):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # 数据移到 GPU\n",
    "            predictions = model(X_batch)\n",
    "            y_true.append(y_batch)\n",
    "            y_pred.append(predictions)\n",
    "    y_true = torch.cat(y_true).cpu().numpy()  # 将数据从 GPU 移回 CPU\n",
    "    y_pred = torch.cat(y_pred).cpu().numpy()\n",
    "    ss_total = ((y_true - y_true.mean()) ** 2).sum()\n",
    "    ss_residual = ((y_true - y_pred) ** 2).sum()\n",
    "    r2 = 1 - ss_residual / ss_total\n",
    "    return r2\n",
    "\n",
    "# 打印训练集和测试集的 R^2 分数\n",
    "r2_train = calculate_r2(train_loader, model)\n",
    "r2_test = calculate_r2(test_loader, model)\n",
    "\n",
    "print(f\"R^2 (Train): {r2_train:.4f}\")\n",
    "print(f\"R^2 (Test): {r2_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5836fa33-ee31-4c7e-b44d-18cfa6cc15e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/2000, Loss: 0.3433\n",
      "Epoch 200/2000, Loss: 0.3061\n",
      "Epoch 300/2000, Loss: 0.2835\n",
      "Epoch 400/2000, Loss: 0.2698\n",
      "Epoch 500/2000, Loss: 0.2576\n",
      "Epoch 600/2000, Loss: 0.2531\n",
      "Epoch 700/2000, Loss: 0.2489\n",
      "Epoch 800/2000, Loss: 0.2423\n",
      "Epoch 900/2000, Loss: 0.2358\n",
      "Epoch 1000/2000, Loss: 0.2329\n",
      "Epoch 1100/2000, Loss: 0.2217\n",
      "Epoch 1200/2000, Loss: 0.2256\n",
      "Epoch 1300/2000, Loss: 0.2259\n",
      "Epoch 1400/2000, Loss: 0.2235\n",
      "Epoch 1500/2000, Loss: 0.2113\n",
      "Epoch 1600/2000, Loss: 0.2129\n",
      "Epoch 1700/2000, Loss: 0.2063\n",
      "Epoch 1800/2000, Loss: 0.2061\n",
      "Epoch 1900/2000, Loss: 0.2082\n",
      "Epoch 2000/2000, Loss: 0.2005\n",
      "Train R^2: 0.8505\n",
      "Test R^2: 0.8184\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 加载数据\n",
    "df = pd.read_csv('housing.csv')\n",
    "X = df[['longitude', 'latitude', 'housing_median_age', 'total_rooms', \n",
    "        'total_bedrooms', 'population', 'households', 'median_income']]\n",
    "y = df['median_house_value']\n",
    "\n",
    "# 数据标准化函数\n",
    "def standardize(data):\n",
    "    mean = torch.mean(data, dim=0)\n",
    "    std = torch.std(data, dim=0)\n",
    "    return (data - mean) / std, mean, std\n",
    "\n",
    "# 转换为 PyTorch 张量\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 标准化数据\n",
    "X, X_mean, X_std = standardize(X)\n",
    "y, y_mean, y_std = standardize(y)\n",
    "\n",
    "# 划分数据集（70%训练，30%测试）\n",
    "dataset_size = len(X)\n",
    "train_size = int(0.7 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "indices = torch.randperm(dataset_size)\n",
    "\n",
    "X_train = X[indices[:train_size]]\n",
    "y_train = y[indices[:train_size]]\n",
    "X_test = X[indices[train_size:]]\n",
    "y_test = y[indices[train_size:]]\n",
    "\n",
    "# 使用 GPU（如果可用）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "# 定义改进的网络结构\n",
    "class ImprovedNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ImprovedNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)   # 第一层，128个神经元\n",
    "        self.bn1 = nn.BatchNorm1d(128)        # 批归一化\n",
    "        self.fc2 = nn.Linear(128, 64)         # 第二层，64个神经元\n",
    "        self.bn2 = nn.BatchNorm1d(64)         # 批归一化\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.3) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x))) \n",
    "        x = self.dropout(x)# 第一层：全连接 + 批归一化 + 激活函数\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)# 第二层\n",
    "        x = torch.relu(self.bn3(self.fc3(x))) \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)                       # 输出层\n",
    "        return x\n",
    "\n",
    "# 初始化网络和优化器\n",
    "input_dim = X_train.shape[1]\n",
    "net = ImprovedNet(input_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# 训练循环\n",
    "epochs = 2000\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = net(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 每100次输出一次损失\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 在测试集上评估\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_train = net(X_train)\n",
    "    y_pred_test = net(X_test)\n",
    "\n",
    "# 计算R方\n",
    "def calculate_r2(y_true, y_pred):\n",
    "    ss_total = ((y_true - y_true.mean()) ** 2).sum()\n",
    "    ss_residual = ((y_true - y_pred) ** 2).sum()\n",
    "    return 1 - (ss_residual / ss_total)\n",
    "\n",
    "r2_train = calculate_r2(y_train, y_pred_train)\n",
    "r2_test = calculate_r2(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Train R^2: {r2_train.item():.4f}\")\n",
    "print(f\"Test R^2: {r2_test.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f147c02-1826-43a7-932b-51f94a86b7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Loss: 0.3381\n",
      "Epoch 200/1000, Loss: 0.3299\n",
      "Epoch 300/1000, Loss: 0.3301\n",
      "Epoch 400/1000, Loss: 0.3279\n",
      "Epoch 500/1000, Loss: 0.3272\n",
      "Epoch 600/1000, Loss: 0.3358\n",
      "Epoch 700/1000, Loss: 0.3364\n",
      "Epoch 800/1000, Loss: 0.3300\n",
      "Epoch 900/1000, Loss: 0.3269\n",
      "Epoch 1000/1000, Loss: 0.3309\n",
      "Train R^2: 0.7307\n",
      "Test R^2: 0.7460\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 加载数据\n",
    "df = pd.read_csv('housing.csv')\n",
    "X = df[['longitude', 'latitude', 'housing_median_age', 'total_rooms', \n",
    "        'total_bedrooms', 'population', 'households', 'median_income']]\n",
    "y = df['median_house_value']\n",
    "\n",
    "# 数据标准化函数\n",
    "def standardize(data):\n",
    "    mean = torch.mean(data, dim=0)\n",
    "    std = torch.std(data, dim=0)\n",
    "    return (data - mean) / std, mean, std\n",
    "\n",
    "# 转换为 PyTorch 张量\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 标准化数据\n",
    "X, X_mean, X_std = standardize(X)\n",
    "y, y_mean, y_std = standardize(y)\n",
    "\n",
    "# 划分数据集（70%训练，30%测试）\n",
    "dataset_size = len(X)\n",
    "train_size = int(0.7 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "indices = torch.randperm(dataset_size)\n",
    "\n",
    "X_train = X[indices[:train_size]]\n",
    "y_train = y[indices[:train_size]]\n",
    "X_test = X[indices[train_size:]]\n",
    "y_test = y[indices[train_size:]]\n",
    "\n",
    "# 使用 GPU（如果可用）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "# 定义更复杂的网络结构\n",
    "class ComplexNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)   # 第一层，128个神经元\n",
    "        self.bn1 = nn.BatchNorm1d(128)        # 批归一化\n",
    "        self.fc2 = nn.Linear(128, 64)         # 第二层，64个神经元\n",
    "        self.bn2 = nn.BatchNorm1d(64)         # 批归一化\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.3) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x))) \n",
    "        x = self.dropout(x)# 第一层：全连接 + 批归一化 + 激活函数\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)# 第二层\n",
    "        x = torch.relu(self.bn3(self.fc3(x))) \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)                       # 输出层\n",
    "        return x\n",
    "\n",
    "# 初始化网络和优化器\n",
    "input_dim = X_train.shape[1]\n",
    "net = ComplexNet(input_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# 动态调整学习率\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "\n",
    "# 训练循环\n",
    "epochs = 1000\n",
    "for epoch in range(1, epochs + 1):\n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = net(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    # 每100次输出一次损失\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 在测试集上评估\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_train = net(X_train)\n",
    "    y_pred_test = net(X_test)\n",
    "\n",
    "# 计算R方\n",
    "def calculate_r2(y_true, y_pred):\n",
    "    ss_total = ((y_true - y_true.mean()) ** 2).sum()\n",
    "    ss_residual = ((y_true - y_pred) ** 2).sum()\n",
    "    return 1 - (ss_residual / ss_total)\n",
    "\n",
    "r2_train = calculate_r2(y_train, y_pred_train)\n",
    "r2_test = calculate_r2(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Train R^2: {r2_train.item():.4f}\")\n",
    "print(f\"Test R^2: {r2_test.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92bb2bb2-0b66-4865-bd68-ae7468c0b2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Train MSE Loss: 0.1444\n",
      "Original Scale Train MSE Loss: 2000575726.0846\n",
      "Train R²: 0.8538\n",
      "\n",
      "Standardized Test MSE Loss: 0.2021\n",
      "Original Scale Test MSE Loss: 2798613302.1529\n",
      "Test R²: 0.8033\n"
     ]
    }
   ],
   "source": [
    "# 定义函数：还原 MSE 到原始尺度\n",
    "def restore_mse(original_std, standardized_mse):\n",
    "    return standardized_mse * (original_std ** 2)\n",
    "\n",
    "# 计算 R² 的函数\n",
    "def calculate_r2(y_true, y_pred):\n",
    "    ss_total = ((y_true - y_true.mean()) ** 2).sum()\n",
    "    ss_residual = ((y_true - y_pred) ** 2).sum()\n",
    "    return 1 - (ss_residual / ss_total)\n",
    "\n",
    "# 在测试集上进行评估\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    # 预测值\n",
    "    y_pred_train = net(X_train)\n",
    "    y_pred_test = net(X_test)\n",
    "    \n",
    "    # 损失计算\n",
    "    train_loss = criterion(y_pred_train, y_train)\n",
    "    test_loss = criterion(y_pred_test, y_test)\n",
    "    \n",
    "    # 还原 MSE 到原始尺度\n",
    "    restored_train_loss = restore_mse(y_std.item(), train_loss.item())\n",
    "    restored_test_loss = restore_mse(y_std.item(), test_loss.item())\n",
    "    \n",
    "    # 计算 R²\n",
    "    r2_train = calculate_r2(y_train, y_pred_train)\n",
    "    r2_test = calculate_r2(y_test, y_pred_test)\n",
    "    \n",
    "    # 输出结果\n",
    "    print(f\"Standardized Train MSE Loss: {train_loss.item():.4f}\")\n",
    "    print(f\"Original Scale Train RMSE Loss: {restored_train_loss:.4f}\")\n",
    "    print(f\"Train R²: {r2_train.item():.4f}\")\n",
    "    print()\n",
    "    print(f\"Standardized Test MSE Loss: {test_loss.item():.4f}\")\n",
    "    print(f\"Original Scale Test RMSE Loss: {restored_test_loss:.4f}\")\n",
    "    print(f\"Test R²: {r2_test.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "602e0ec4-c96c-42de-9071-50379c195737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/2000, Loss: 0.3233\n",
      "Epoch 200/2000, Loss: 0.2810\n",
      "Epoch 300/2000, Loss: 0.2577\n",
      "Epoch 400/2000, Loss: 0.2494\n",
      "Epoch 500/2000, Loss: 0.2407\n",
      "Epoch 600/2000, Loss: 0.2368\n",
      "Epoch 700/2000, Loss: 0.2298\n",
      "Epoch 800/2000, Loss: 0.2275\n",
      "Epoch 900/2000, Loss: 0.2227\n",
      "Epoch 1000/2000, Loss: 0.2208\n",
      "Epoch 1100/2000, Loss: 0.2150\n",
      "Epoch 1200/2000, Loss: 0.2129\n",
      "Epoch 1300/2000, Loss: 0.2121\n",
      "Epoch 1400/2000, Loss: 0.2100\n",
      "Epoch 1500/2000, Loss: 0.2090\n",
      "Epoch 1600/2000, Loss: 0.2029\n",
      "Epoch 1700/2000, Loss: 0.2054\n",
      "Epoch 1800/2000, Loss: 0.2048\n",
      "Epoch 1900/2000, Loss: 0.2041\n",
      "Epoch 2000/2000, Loss: 0.1994\n",
      "训练集 R^2: 0.8330\n",
      "测试集 R^2: 0.8018\n",
      "训练集 RMSE: 47822.3516\n",
      "测试集 RMSE: 53047.9922\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "df = pd.read_csv('housing.csv')\n",
    "X = df[['longitude', 'latitude', 'housing_median_age', 'total_rooms', \n",
    "        'total_bedrooms', 'population', 'households', 'median_income']]\n",
    "y = df['median_house_value']\n",
    "\n",
    "# 数据标准化函数\n",
    "def standardize(data):\n",
    "    mean = torch.mean(data, dim=0)\n",
    "    std = torch.std(data, dim=0)\n",
    "    return (data - mean) / std, mean, std\n",
    "\n",
    "# 转换为 PyTorch 张量\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 标准化数据\n",
    "X, X_mean, X_std = standardize(X)\n",
    "y, y_mean, y_std = standardize(y)\n",
    "\n",
    "# 划分数据集（70%训练，30%测试）\n",
    "dataset_size = len(X)\n",
    "train_size = int(0.7 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "indices = torch.randperm(dataset_size)\n",
    "\n",
    "X_train = X[indices[:train_size]]\n",
    "y_train = y[indices[:train_size]]\n",
    "X_test = X[indices[train_size:]]\n",
    "y_test = y[indices[train_size:]]\n",
    "\n",
    "# 使用 GPU（如果可用）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "# 定义改进的网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)   # 第一层，128个神经元\n",
    "        self.bn1 = nn.BatchNorm1d(128)        # 批归一化\n",
    "        self.fc2 = nn.Linear(128, 64)         # 第二层，64个神经元\n",
    "        self.bn2 = nn.BatchNorm1d(64)         # 批归一化\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(0.3) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x))) \n",
    "        x = self.dropout(x)  # 第一层：全连接 + 批归一化 + 激活函数\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)  # 第二层\n",
    "        x = self.fc3(x)  # 输出层\n",
    "        return x\n",
    "\n",
    "# 初始化网络和优化器\n",
    "input_dim = X_train.shape[1]\n",
    "net = ImprovedNet(input_dim).to(device)\n",
    "criterion = nn.MSELoss()  # 使用MSE作为损失函数\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# 训练循环\n",
    "epochs = 2000\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = net(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 每100次输出一次损失\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 在测试集上评估\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_train = net(X_train)\n",
    "    y_pred_test = net(X_test)\n",
    "\n",
    "# 计算R方\n",
    "def calculate_r2(y_true, y_pred):\n",
    "    ss_total = ((y_true - y_true.mean()) ** 2).sum()\n",
    "    ss_residual = ((y_true - y_pred) ** 2).sum()\n",
    "    return 1 - (ss_residual / ss_total)\n",
    "\n",
    "r2_train = calculate_r2(y_train, y_pred_train)\n",
    "r2_test = calculate_r2(y_test, y_pred_test)\n",
    "\n",
    "print(f\"训练集 R^2: {r2_train.item():.4f}\")\n",
    "print(f\"测试集 R^2: {r2_test.item():.4f}\")\n",
    "\n",
    "# 计算RMSE\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    mse = torch.mean((y_true - y_pred) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "# 还原RMSE到原始尺度\n",
    "def restore_rmse(y_std, rmse):\n",
    "    # 确保 y_std 和 rmse 在相同的设备上\n",
    "    y_std = y_std.to(rmse.device)\n",
    "    return rmse * y_std\n",
    "\n",
    "# 计算标准化后的RMSE\n",
    "train_rmse = calculate_rmse(y_train, y_pred_train)\n",
    "test_rmse = calculate_rmse(y_test, y_pred_test)\n",
    "\n",
    "# 还原到原始尺度\n",
    "restored_train_rmse = restore_rmse(y_std, train_rmse)\n",
    "restored_test_rmse = restore_rmse(y_std, test_rmse)\n",
    "\n",
    "# 输出时将Tensor转换为标量\n",
    "print(f\"训练集 RMSE: {restored_train_rmse.item():.4f}\")\n",
    "print(f\"测试集 RMSE: {restored_test_rmse.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a1220d0-12d5-4164-a1ea-1551eaaa39a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/2000, Loss: 0.3221\n",
      "Epoch 200/2000, Loss: 0.2843\n",
      "Epoch 300/2000, Loss: 0.2706\n",
      "Epoch 400/2000, Loss: 0.2563\n",
      "Epoch 500/2000, Loss: 0.2474\n",
      "Epoch 600/2000, Loss: 0.2389\n",
      "Epoch 700/2000, Loss: 0.2384\n",
      "Epoch 800/2000, Loss: 0.2339\n",
      "Epoch 900/2000, Loss: 0.2293\n",
      "Epoch 1000/2000, Loss: 0.2274\n",
      "Epoch 1100/2000, Loss: 0.2213\n",
      "Epoch 1200/2000, Loss: 0.2198\n",
      "Epoch 1300/2000, Loss: 0.2194\n",
      "Epoch 1400/2000, Loss: 0.2200\n",
      "Epoch 1500/2000, Loss: 0.2123\n",
      "Epoch 1600/2000, Loss: 0.2172\n",
      "Epoch 1700/2000, Loss: 0.2071\n",
      "Epoch 1800/2000, Loss: 0.2063\n",
      "Epoch 1900/2000, Loss: 0.2052\n",
      "Epoch 2000/2000, Loss: 0.2050\n",
      "Train R^2: 0.8325\n",
      "Test R^2: 0.7978\n",
      "Standardized Train RMSE: 0.4121\n",
      "Standardized Test RMSE: 0.4423\n",
      "Original Scale Train RMSE: 48498.4609\n",
      "Original Scale Test RMSE: 52050.0117\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "df = pd.read_csv('housing.csv')\n",
    "X = df[['longitude', 'latitude', 'housing_median_age', 'total_rooms', \n",
    "        'total_bedrooms', 'population', 'households', 'median_income']]\n",
    "y = df['median_house_value']\n",
    "\n",
    "# 数据标准化函数\n",
    "def standardize(data):\n",
    "    mean = torch.mean(data, dim=0)\n",
    "    std = torch.std(data, dim=0)\n",
    "    return (data - mean) / std, mean, std\n",
    "\n",
    "# 转换为 PyTorch 张量\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 标准化数据\n",
    "X, X_mean, X_std = standardize(X)\n",
    "y, y_mean, y_std = standardize(y)\n",
    "\n",
    "# 划分数据集（70%训练，30%测试）\n",
    "dataset_size = len(X)\n",
    "train_size = int(0.7 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "indices = torch.randperm(dataset_size)\n",
    "\n",
    "X_train = X[indices[:train_size]]\n",
    "y_train = y[indices[:train_size]]\n",
    "X_test = X[indices[train_size:]]\n",
    "y_test = y[indices[train_size:]]\n",
    "\n",
    "# 使用 GPU（如果可用）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "# 定义改进的网络结构\n",
    "class ImprovedNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ImprovedNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)   # 第一层，128个神经元\n",
    "        self.bn1 = nn.BatchNorm1d(128)        # 批归一化\n",
    "        self.fc2 = nn.Linear(128, 64)         # 第二层，64个神经元\n",
    "        self.bn2 = nn.BatchNorm1d(64)         # 批归一化\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(0.3) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x))) \n",
    "        x = self.dropout(x)  # 第一层：全连接 + 批归一化 + 激活函数\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)  # 第二层\n",
    "        x = self.fc3(x)  # 输出层\n",
    "        return x\n",
    "\n",
    "# 初始化网络和优化器\n",
    "input_dim = X_train.shape[1]\n",
    "net = ImprovedNet(input_dim).to(device)\n",
    "criterion = nn.MSELoss()  # 使用MSE作为损失函数\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# 训练循环\n",
    "epochs = 2000\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = net(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 每100次输出一次损失\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 在测试集上评估\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_train = net(X_train)\n",
    "    y_pred_test = net(X_test)\n",
    "\n",
    "# 计算R方\n",
    "def calculate_r2(y_true, y_pred):\n",
    "    ss_total = ((y_true - y_true.mean()) ** 2).sum()\n",
    "    ss_residual = ((y_true - y_pred) ** 2).sum()\n",
    "    return 1 - (ss_residual / ss_total)\n",
    "\n",
    "r2_train = calculate_r2(y_train, y_pred_train)\n",
    "r2_test = calculate_r2(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Train R^2: {r2_train.item():.4f}\")\n",
    "print(f\"Test R^2: {r2_test.item():.4f}\")\n",
    "\n",
    "# 计算RMSE\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    mse = torch.mean((y_true - y_pred) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "# 还原RMSE到原始尺度\n",
    "def restore_rmse(y_std, rmse):\n",
    "    # 确保 y_std 和 rmse 在相同的设备上\n",
    "    y_std = y_std.to(rmse.device)\n",
    "    return rmse * y_std\n",
    "\n",
    "# 计算标准化后的RMSE\n",
    "train_rmse = calculate_rmse(y_train, y_pred_train)\n",
    "test_rmse = calculate_rmse(y_test, y_pred_test)\n",
    "\n",
    "# 还原到原始尺度\n",
    "restored_train_rmse = restore_rmse(y_std, train_rmse)\n",
    "restored_test_rmse = restore_rmse(y_std, test_rmse)\n",
    "\n",
    "# 输出时将Tensor转换为标量\n",
    "print(f\"Standardized Train RMSE: {train_rmse.item():.4f}\")\n",
    "print(f\"Standardized Test RMSE: {test_rmse.item():.4f}\")\n",
    "print(f\"Original Scale Train RMSE: {restored_train_rmse.item():.4f}\")\n",
    "print(f\"Original Scale Test RMSE: {restored_test_rmse.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e81f9-3a82-45e7-9036-c53c619e59b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
